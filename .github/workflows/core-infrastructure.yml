name: Core Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action'
        required: true
        type: choice
        options:
        - deploy
        - destroy
        - plan
      environment:
        description: 'Network/Environment'
        required: true
        default: 'lower'
        type: choice
        options:
        - lower
        - higher
        - monitoring
        - all
      confirm_destroy:
        description: 'Type "DESTROY" to confirm'
        required: false
        type: string
      restore_from_snapshot:
        description: 'Restore RDS from snapshot'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: ap-south-1
  TERRAFORM_VERSION: 1.6.0

jobs:
  infrastructure:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: write
    strategy:
      matrix:
        env: ${{ github.event.inputs.environment == 'all' && fromJson('["lower", "higher", "monitoring"]') || fromJson(format('["{0}"]', github.event.inputs.environment)) }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}



    - name: Terraform Init
      working-directory: infra
      run: |
        terraform init \
          -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
          -backend-config="key=health-app-${{ matrix.env }}.tfstate" \
          -backend-config="region=$AWS_REGION"

    - name: Terraform Plan
      working-directory: infra
      if: github.event.inputs.action == 'plan' || github.event.inputs.action == 'deploy'
      run: |
        terraform plan \
          -var-file="environments/${{ matrix.env }}.tfvars" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -var="restore_from_snapshot=${{ github.event.inputs.restore_from_snapshot }}" \
          -out=tfplan

    - name: Terraform Apply
      id: terraform-apply
      working-directory: infra
      if: github.event.inputs.action == 'deploy'
      run: terraform apply -auto-approve tfplan

    - name: Terraform Destroy
      working-directory: infra
      if: github.event.inputs.action == 'destroy' && github.event.inputs.confirm_destroy == 'DESTROY'
      run: |
        terraform destroy \
          -var-file="environments/${{ matrix.env }}.tfvars" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -var="restore_from_snapshot=${{ github.event.inputs.restore_from_snapshot }}" \
          -auto-approve

    - name: Cleanup kubeconfig from S3
      if: github.event.inputs.action == 'destroy' && github.event.inputs.confirm_destroy == 'DESTROY'
      run: |
        echo "🧹 Cleaning up kubeconfig files from S3..."
        
        # Remove main kubeconfig
        aws s3 rm s3://${{ secrets.TF_STATE_BUCKET }}/kubeconfig/${{ matrix.env }}-network.yaml 2>/dev/null || echo "Main kubeconfig not found"
        
        # Remove environment-specific copies
        case "${{ matrix.env }}" in
          "lower")
            aws s3 rm s3://${{ secrets.TF_STATE_BUCKET }}/kubeconfig/dev-network.yaml 2>/dev/null || echo "Dev kubeconfig not found"
            aws s3 rm s3://${{ secrets.TF_STATE_BUCKET }}/kubeconfig/test-network.yaml 2>/dev/null || echo "Test kubeconfig not found"
            ;;
          "higher")
            aws s3 rm s3://${{ secrets.TF_STATE_BUCKET }}/kubeconfig/prod-network.yaml 2>/dev/null || echo "Prod kubeconfig not found"
            ;;
          "monitoring")
            # No additional copies for monitoring
            ;;
        esac
        
        echo "✅ Kubeconfig cleanup completed"



    - name: Install yq
      if: github.event.inputs.action == 'deploy'
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq

    - name: Create and upload kubeconfig to S3
      if: github.event.inputs.action == 'deploy'
      working-directory: infra
      run: |
        CLUSTER_IP=$(terraform output -raw k3s_instance_ip 2>/dev/null || echo "")
        
        if [[ -z "$CLUSTER_IP" || "$CLUSTER_IP" == "null" ]]; then
          echo "❌ Cluster IP not found. Skipping kubeconfig generation."
          exit 1
        fi

        KUBECONFIG_FILE="/tmp/kubeconfig.yaml"

        yq eval -n --arg ip "$CLUSTER_IP" --arg token "K10..." '
          {
            apiVersion: "v1",
            kind: "Config",
            preferences: {},
            "current-context": "default",
            clusters: [
              {
                name: "default",
                cluster: {
                  server: "https://\($ip):6443",
                  "insecure-skip-tls-verify": true
                }
              }
            ],
            contexts: [
              {
                name: "default",
                context: {
                  cluster: "default",
                  user: "default"
                }
              }
            ],
            users: [
              {
                name: "default",
                user: {
                  token: $token
                }
              }
            ]
          }
        ' > "$KUBECONFIG_FILE"

        echo "✅ Kubeconfig generated for $CLUSTER_IP"

        DEST_BUCKET="s3://${{ secrets.TF_STATE_BUCKET }}/kubeconfig"
        aws s3 cp "$KUBECONFIG_FILE" "$DEST_BUCKET/${{ matrix.env }}-network.yaml"

        case "${{ matrix.env }}" in
          "lower")
            aws s3 cp "$KUBECONFIG_FILE" "$DEST_BUCKET/dev-network.yaml"
            aws s3 cp "$KUBECONFIG_FILE" "$DEST_BUCKET/test-network.yaml"
            ;;
          "higher")
            aws s3 cp "$KUBECONFIG_FILE" "$DEST_BUCKET/prod-network.yaml"
            ;;
        esac

        echo "✅ Uploaded kubeconfig to S3"

    - name: Cleanup on Failure
      if: failure() && github.event.inputs.action == 'deploy' && steps.terraform-apply.outcome == 'failure'
      working-directory: infra
      run: |
        echo "🧹 Terraform deployment failed - cleaning up partial resources"
        
        terraform destroy \
          -var-file="environments/${{ matrix.env }}.tfvars" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -auto-approve || echo "Cleanup completed (some errors expected)"
        
        echo "✅ Cleanup completed - safe to retry deployment"

    - name: Summary
      if: always()
      working-directory: infra
      run: |
        echo "## 🏗️ Infrastructure ${{ github.event.inputs.action }} - ${{ matrix.env }}" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        echo "**Environment:** ${{ matrix.env }}" >> $GITHUB_STEP_SUMMARY
        echo "**Date:** $(date)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ job.status }}" == "success" && "${{ github.event.inputs.action }}" == "deploy" ]]; then
          echo "### ✅ Resources Created" >> $GITHUB_STEP_SUMMARY
          
          # Get Terraform outputs
          CLUSTER_IP=$(terraform output -raw k3s_instance_ip 2>/dev/null || echo "Not available")
          DB_ENDPOINT=$(terraform output -raw db_instance_endpoint 2>/dev/null || echo "Not available")
          VPC_ID=$(terraform output -raw vpc_id 2>/dev/null || echo "Not available")
          
          echo "- **VPC:** $VPC_ID" >> $GITHUB_STEP_SUMMARY
          echo "- **K3s Cluster:** $CLUSTER_IP:6443" >> $GITHUB_STEP_SUMMARY
          echo "- **Database:** $DB_ENDPOINT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 📁 S3 Kubeconfig Files" >> $GITHUB_STEP_SUMMARY
          
          # Check kubeconfig files in S3
          S3_BUCKET="s3://${{ secrets.TF_STATE_BUCKET }}/kubeconfig"
          
          if aws s3 ls "$S3_BUCKET/${{ matrix.env }}-network.yaml" >/dev/null 2>&1; then
            echo "- ✅ **${{ matrix.env }}-network.yaml** - Uploaded successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "- ❌ **${{ matrix.env }}-network.yaml** - Upload failed" >> $GITHUB_STEP_SUMMARY
          fi
          
          case "${{ matrix.env }}" in
            "lower")
              if aws s3 ls "$S3_BUCKET/dev-network.yaml" >/dev/null 2>&1; then
                echo "- ✅ **dev-network.yaml** - Copy created" >> $GITHUB_STEP_SUMMARY
              else
                echo "- ❌ **dev-network.yaml** - Copy failed" >> $GITHUB_STEP_SUMMARY
              fi
              if aws s3 ls "$S3_BUCKET/test-network.yaml" >/dev/null 2>&1; then
                echo "- ✅ **test-network.yaml** - Copy created" >> $GITHUB_STEP_SUMMARY
              else
                echo "- ❌ **test-network.yaml** - Copy failed" >> $GITHUB_STEP_SUMMARY
              fi
              ;;
            "higher")
              if aws s3 ls "$S3_BUCKET/prod-network.yaml" >/dev/null 2>&1; then
                echo "- ✅ **prod-network.yaml** - Copy created" >> $GITHUB_STEP_SUMMARY
              else
                echo "- ❌ **prod-network.yaml** - Copy failed" >> $GITHUB_STEP_SUMMARY
              fi
              ;;
          esac
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🚀 Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "1. Run **Core Deployment** workflow" >> $GITHUB_STEP_SUMMARY
          echo "2. Select environment: dev/test/prod" >> $GITHUB_STEP_SUMMARY
          echo "3. Kubeconfig will be auto-downloaded from S3" >> $GITHUB_STEP_SUMMARY
          
        elif [[ "${{ job.status }}" == "success" && "${{ github.event.inputs.action }}" == "destroy" ]]; then
          echo "### 🗑️ Resources Destroyed" >> $GITHUB_STEP_SUMMARY
          echo "- All infrastructure resources removed" >> $GITHUB_STEP_SUMMARY
          echo "- Kubeconfig files cleaned from S3" >> $GITHUB_STEP_SUMMARY
          
        elif [[ "${{ job.status }}" == "success" && "${{ github.event.inputs.action }}" == "plan" ]]; then
          echo "### 📋 Plan Generated" >> $GITHUB_STEP_SUMMARY
          echo "- Review the plan output above" >> $GITHUB_STEP_SUMMARY
          echo "- Run deploy action to apply changes" >> $GITHUB_STEP_SUMMARY
          
        elif [[ "${{ job.status }}" == "failure" ]]; then
          echo "### ❌ Deployment Failed" >> $GITHUB_STEP_SUMMARY
          echo "- Check logs for error details" >> $GITHUB_STEP_SUMMARY
          echo "- Partial resources may have been cleaned up" >> $GITHUB_STEP_SUMMARY
          echo "- Safe to retry deployment" >> $GITHUB_STEP_SUMMARY
        fi