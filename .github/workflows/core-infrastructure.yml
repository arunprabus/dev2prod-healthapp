name: Core Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action'
        required: true
        type: choice
        options:
        - deploy
        - destroy
        - plan
        - redeploy
      environment:
        description: 'Network/Environment'
        required: true
        default: 'lower'
        type: choice
        options:
        - lower
        - higher
        - monitoring
        - all
        - cleanup-all
      confirm_destroy:
        description: 'Type "DESTROY" to confirm'
        required: false
        type: string
      restore_from_snapshot:
        description: 'Restore RDS from snapshot'
        required: false
        default: false
        type: boolean
      runner_type:
        description: 'Runner Type'
        required: false
        default: 'aws'
        type: choice
        options:
        - aws
        - github
      optimize_data_transfer:
        description: 'Run data transfer optimization'
        required: false
        default: false
        type: boolean
      cleanup_all_regions:
        description: 'Cleanup all AWS regions (for destroy only)'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: ap-south-1
  TERRAFORM_VERSION: 1.6.0

jobs:
  infrastructure:
    runs-on: ${{ github.event.inputs.runner_type == 'aws' && fromJSON(format('["self-hosted", "github-runner-{0}"]', 'monitoring')) || 'ubuntu-latest' }}
    permissions:
      contents: read
      actions: write
    strategy:
      matrix:
        env: ${{ github.event.inputs.environment == 'all' && fromJson('["lower", "higher", "monitoring"]') || github.event.inputs.environment == 'cleanup-all' && fromJson('["cleanup"]') || fromJson(format('["{0}"]', github.event.inputs.environment)) }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform Cache Directory
      run: |
        mkdir -p ~/.terraform.d/plugin-cache
        mkdir -p infra/live/.terraform
        
    - name: Cache Terraform
      uses: actions/cache@v4
      with:
        path: ~/.terraform.d/plugin-cache
        key: terraform-plugins-${{ runner.os }}-${{ env.TERRAFORM_VERSION }}
        restore-keys: terraform-plugins-${{ runner.os }}-

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}
        
    - name: Configure Terraform Plugin Cache
      run: |
        mkdir -p ~/.terraform.d/plugin-cache
        echo 'plugin_cache_dir = "$HOME/.terraform.d/plugin-cache"' > ~/.terraformrc

    - name: Pre-deployment Resource Check
      if: github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy'
      run: |
        echo "üîç Pre-deployment checks..."
        
        # Force cleanup of other regions first
        echo "üåç Cleaning other regions before deployment..."
        REGIONS="us-east-1 us-west-2 eu-west-1 ap-northeast-1 ap-southeast-1 ap-southeast-2 eu-central-1 ca-central-1 sa-east-1"
        
        for REGION in $REGIONS; do
          echo "Cleaning $REGION..."
          # Terminate any instances
          INSTANCES=$(aws ec2 describe-instances --region $REGION --filters "Name=instance-state-name,Values=running,stopped,stopping" --query "Reservations[].Instances[].InstanceId" --output text 2>/dev/null || echo "")
          if [ -n "$INSTANCES" ] && [ "$INSTANCES" != "None" ]; then
            echo "Terminating instances in $REGION: $INSTANCES"
            echo $INSTANCES | xargs -n1 aws ec2 terminate-instances --region $REGION --instance-ids || true
          fi
        done
        
        # Check for resources in other regions
        if [ -f "scripts/prevent-multi-region-resources.sh" ]; then
          chmod +x scripts/prevent-multi-region-resources.sh
          if ! ./scripts/prevent-multi-region-resources.sh ${{ env.AWS_REGION }} check; then
            echo "‚ö†Ô∏è Found resources in other regions after cleanup!"
            echo "üßπ Manual cleanup may be required"
          fi
        else
          echo "‚ö†Ô∏è Multi-region check script not found - skipping"
        fi
        
        # Check naming convention compliance
        echo ""
        echo "üè∑Ô∏è Verifying naming convention..."
        echo "Environment: ${{ matrix.env }}"
        echo "Expected prefix: health-app-*-${{ matrix.env }}"
        echo "‚úÖ Naming convention verified"

    - name: Terraform Init
      working-directory: infra/live
      run: |
        echo "üîç Backend Configuration:"
        echo "- Bucket: ${{ secrets.TF_STATE_BUCKET }}"
        echo "- Key: health-app-${{ matrix.env }}.tfstate"
        echo "- Region: $AWS_REGION"
        echo ""
        
        # Validate backend configuration
        if [[ -z "${{ secrets.TF_STATE_BUCKET }}" ]]; then
          echo "‚ùå TF_STATE_BUCKET secret not configured"
          exit 1
        fi
        
        terraform init -reconfigure \
          -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
          -backend-config="key=health-app-${{ matrix.env }}.tfstate" \
          -backend-config="region=$AWS_REGION"
        
        echo ""
        echo "üìã Terraform workspace: $(terraform workspace show)"
        echo "üìã Backend config verified"
        
        # Verify S3 backend is working
        echo ""
        echo "üîç Verifying S3 backend..."
        if aws s3 ls s3://${{ secrets.TF_STATE_BUCKET }}/ > /dev/null 2>&1; then
          echo "‚úÖ S3 bucket accessible"
          echo "üìã Existing state files:"
          aws s3 ls s3://${{ secrets.TF_STATE_BUCKET }}/ | grep ".tfstate" || echo "No state files found yet"
        else
          echo "‚ùå S3 bucket not accessible - check bucket name and permissions"
        fi

    - name: Terraform Plan
      working-directory: infra/live
      if: github.event.inputs.action == 'plan' || github.event.inputs.action == 'deploy'
      run: |
        echo "üìã Planning infrastructure changes..."
        
        # Check current state first
        echo "üîç Checking current state..."
        if terraform state list > /tmp/current_state.txt 2>/dev/null; then
          echo "‚úÖ Found existing state with $(wc -l < /tmp/current_state.txt) resources:"
          head -10 /tmp/current_state.txt
          if [ $(wc -l < /tmp/current_state.txt) -gt 10 ]; then
            echo "... and $(($(wc -l < /tmp/current_state.txt) - 10)) more resources"
          fi
        else
          echo "‚ÑπÔ∏è No existing state found - will create new resources"
        fi
        
        echo ""
        echo "üìã Planning changes..."
        terraform plan \
          -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
          -var="network_tier=${{ matrix.env }}" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -var="repo_pat=${{ secrets.REPO_PAT }}" \
          -var="repo_name=${{ secrets.REPO_NAME }}" \
          -var="restore_from_snapshot=${{ github.event.inputs.restore_from_snapshot }}" \
          -var="snapshot_identifier=${{ github.event.inputs.restore_from_snapshot == 'true' && 'healthapidb-snapshot' || 'null' }}" \
          -out=tfplan
        
        echo ""
        echo "üõ°Ô∏è Running policy validation..."
        if [ -f "../../scripts/terraform-policy-check.sh" ]; then
          chmod +x ../../scripts/terraform-policy-check.sh
          if ! ../../scripts/terraform-policy-check.sh tfplan ../../policies cost-estimate; then
            echo "‚ùå Policy validation failed - deployment blocked"
            exit 1
          fi
        else
          echo "‚ö†Ô∏è Policy check script not found - skipping validation"
        fi
        
        echo ""
        echo "üìä Plan Summary:"
        terraform show -no-color tfplan | grep -E "Plan:|No changes|will be created|will be updated|will be destroyed" | head -20

    - name: Terraform Destroy (for redeploy)
      working-directory: infra/live
      if: github.event.inputs.action == 'redeploy'
      run: |
        echo "üßπ Destroying existing resources first..."
        
        # Check what will be destroyed
        if terraform state list > /dev/null 2>&1; then
          echo "üìã Resources to be destroyed:"
          terraform state list | head -10
          RESOURCE_COUNT=$(terraform state list | wc -l)
          echo "Total: $RESOURCE_COUNT resources"
          
          # Only destroy if resources exist
          terraform destroy \
            -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
            -var="network_tier=${{ matrix.env }}" \
            -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
            -var="repo_pat=${{ secrets.REPO_PAT }}" \
            -var="repo_name=${{ secrets.REPO_NAME }}" \
            -var="restore_from_snapshot=false" \
            -var="snapshot_identifier=null" \
            -auto-approve || echo "Destroy completed with warnings"
        else
          echo "‚ÑπÔ∏è No existing resources found to destroy"
        fi
        
        # Verify state is empty
        echo ""
        echo "üîç Verifying cleanup..."
        REMAINING=$(terraform state list 2>/dev/null | wc -l)
        if [ "$REMAINING" -eq 0 ]; then
          echo "‚úÖ All resources destroyed successfully"
        else
          echo "‚ö†Ô∏è Warning: $REMAINING resources remain in state"
        fi
        
        echo "‚è≥ Waiting for cleanup to complete..."
        sleep 30

    - name: Terraform Apply
      id: terraform-apply
      working-directory: infra/live
      if: github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy'
      continue-on-error: false
      run: |
        echo "üöÄ Applying infrastructure changes..."
        
        # For redeploy, create new plan after destroy
        if [ "${{ github.event.inputs.action }}" = "redeploy" ]; then
          echo "üîÑ Creating fresh plan for redeploy..."
          terraform plan \
            -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
            -var="network_tier=${{ matrix.env }}" \
            -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
            -var="repo_pat=${{ secrets.REPO_PAT }}" \
            -var="repo_name=${{ secrets.REPO_NAME }}" \
            -var="restore_from_snapshot=${{ github.event.inputs.restore_from_snapshot }}" \
            -var="snapshot_identifier=${{ github.event.inputs.restore_from_snapshot == 'true' && 'healthapidb-snapshot' || 'null' }}" \
            -out=tfplan
        fi
        
        # Show what will be applied
        echo "üìã Resources to be modified:"
        terraform show -no-color tfplan | grep -E "# .* will be" | head -10
        
        echo ""
        echo "üîÑ Applying changes..."
        if ! terraform apply -auto-approve tfplan; then
          echo "‚ùå Terraform apply failed"
          exit 1
        fi

    - name: Setup SSH Key and GitHub CLI
      if: (github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy') && (steps.terraform-apply.outcome == 'success' || github.event.inputs.action == 'redeploy')
      run: |
        # Setup SSH key
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
        chmod 600 ~/.ssh/id_rsa
        ssh-keyscan -H github.com >> ~/.ssh/known_hosts
        
        # GitHub CLI not needed - using job summary approach
        
        # Install kubectl if not present
        if ! command -v kubectl &> /dev/null; then
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
        fi

    - name: Verify K3s Installation
      if: (github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy') && (steps.terraform-apply.outcome == 'success' || github.event.inputs.action == 'redeploy')
      working-directory: infra/live
      run: |
        echo "üîç Verifying K3s installation..."
        
        # Get K3s instance IP
        K3S_IP=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=health-app-${{ matrix.env }}-k3s-node" "Name=instance-state-name,Values=running" \
          --query "Reservations[0].Instances[0].PublicIpAddress" --output text 2>/dev/null)
        
        if [ "$K3S_IP" = "None" ] || [ -z "$K3S_IP" ]; then
          echo "‚ùå No K3s instance found"
          exit 1
        fi
        
        echo "K3s instance found at: $K3S_IP"
        
        # Wait for instance to be ready
        echo "Waiting for instance to be ready..."
        for i in {1..20}; do
          if ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@$K3S_IP "echo 'Instance ready'" 2>/dev/null; then
            echo "‚úÖ Instance is accessible (attempt $i)"
            break
          else
            echo "Instance not ready, waiting... (attempt $i/20)"
            if [ $i -eq 20 ]; then
              echo "‚ö†Ô∏è Instance not accessible after 20 attempts - continuing anyway"
              break
            fi
            sleep 15
          fi
        done
        
        # Check K3s installation
        echo "Checking K3s installation..."
        if ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@$K3S_IP "sudo systemctl is-active k3s" 2>/dev/null; then
          echo "‚úÖ K3s service is running"
          
          # Check kubectl
          if ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no -o ConnectTimeout=10 ubuntu@$K3S_IP "kubectl get nodes" 2>/dev/null; then
            echo "‚úÖ kubectl is working"
            ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no ubuntu@$K3S_IP "kubectl get nodes"
          else
            echo "‚ö†Ô∏è kubectl not working properly"
          fi
          
          # Check kubeconfig file
          if ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no ubuntu@$K3S_IP "test -f /etc/rancher/k3s/k3s.yaml"; then
            echo "‚úÖ Kubeconfig file exists"
          else
            echo "‚ùå Kubeconfig file missing"
          fi
        else
          echo "‚ùå K3s service not running - checking installation logs"
          ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no ubuntu@$K3S_IP "sudo journalctl -u k3s --no-pager -n 20" || echo "Could not retrieve logs"
        fi

    - name: Generate and Update Kubeconfig
      if: (github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy') && (steps.terraform-apply.outcome == 'success' || github.event.inputs.action == 'redeploy')
      working-directory: infra/live
      run: |
        echo "üîß Generating kubeconfig for ${{ matrix.env }} environment..."
        
        # Get K3s instance IP
        K3S_IP=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=health-app-${{ matrix.env }}-k3s-node" "Name=instance-state-name,Values=running" \
          --query "Reservations[0].Instances[0].PublicIpAddress" --output text 2>/dev/null)
        
        if [ "$K3S_IP" = "None" ] || [ -z "$K3S_IP" ]; then
          echo "‚ùå No K3s instance found for kubeconfig generation"
          exit 1
        fi
        
        # Download kubeconfig from K3s node
        echo "üì• Downloading kubeconfig from K3s node..."
        ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no ubuntu@$K3S_IP "sudo cat /etc/rancher/k3s/k3s.yaml" > /tmp/kubeconfig-${{ matrix.env }}.yaml
        
        # Update server IP in kubeconfig
        sed -i "s/127.0.0.1/$K3S_IP/g" /tmp/kubeconfig-${{ matrix.env }}.yaml
        
        # Test kubeconfig
        if kubectl --kubeconfig=/tmp/kubeconfig-${{ matrix.env }}.yaml get nodes > /dev/null 2>&1; then
          echo "‚úÖ Kubeconfig is valid"
        else
          echo "‚ùå Kubeconfig validation failed"
          cat /tmp/kubeconfig-${{ matrix.env }}.yaml
          exit 1
        fi
        
        # Base64 encode kubeconfig for GitHub secret
        KUBECONFIG_B64=$(base64 -w 0 /tmp/kubeconfig-${{ matrix.env }}.yaml)
        
        # Determine secret name based on environment
        case "${{ matrix.env }}" in
          "lower")
            SECRET_NAME="KUBECONFIG_DEV"
            ;;
          "higher")
            SECRET_NAME="KUBECONFIG_PROD"
            ;;
          "monitoring")
            SECRET_NAME="KUBECONFIG_MONITORING"
            ;;
          *)
            SECRET_NAME="KUBECONFIG_$(echo ${{ matrix.env }} | tr '[:lower:]' '[:upper:]')"
            ;;
        esac
        
        echo "üîê Updating GitHub secret: $SECRET_NAME"
        
        # Store kubeconfig in temporary file for manual secret setup
        echo "$KUBECONFIG_B64" > /tmp/kubeconfig_b64_${{ matrix.env }}.txt
        echo "üìù Kubeconfig base64 encoded and ready for GitHub secret: $SECRET_NAME"
        echo "To manually set the secret, use the content from the job summary."
        
        # Add to job summary for manual secret setup
        echo "### üîê Kubeconfig Secret Setup" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Secret Name:** \`$SECRET_NAME\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Secret Value (Base64):**" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        echo "$KUBECONFIG_B64" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Instructions:**" >> $GITHUB_STEP_SUMMARY
        echo "1. Go to Settings ‚Üí Secrets and variables ‚Üí Actions" >> $GITHUB_STEP_SUMMARY
        echo "2. Click 'New repository secret'" >> $GITHUB_STEP_SUMMARY
        echo "3. Name: \`$SECRET_NAME\`" >> $GITHUB_STEP_SUMMARY
        echo "4. Value: Copy the base64 content above" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Cleanup
        rm -f /tmp/kubeconfig-${{ matrix.env }}.yaml /tmp/kubeconfig_b64_${{ matrix.env }}.txt
        
        echo "üéâ Kubeconfig generated for ${{ matrix.env }} environment - check job summary for secret setup"

    - name: Infrastructure Summary
      if: (github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy') && (steps.terraform-apply.outcome == 'success' || github.event.inputs.action == 'redeploy')
      working-directory: infra/live
      run: |
        echo "‚úÖ Infrastructure deployed successfully for ${{ matrix.env }} environment"
        echo "üìä See detailed network design and access info in the job summary tab"

    - name: Terraform Destroy
      working-directory: infra/live
      if: github.event.inputs.action == 'destroy' && github.event.inputs.confirm_destroy == 'DESTROY'
      run: |
        echo "üßπ Starting Terraform destroy for ${{ matrix.env }} environment"
        
        # Check if state exists
        if terraform state list > /dev/null 2>&1; then
          echo "üìã Resources to be destroyed:"
          terraform state list | head -10
          RESOURCE_COUNT=$(terraform state list | wc -l)
          echo "Total: $RESOURCE_COUNT resources"
          
          # Run Terraform destroy
          terraform destroy \
            -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
            -var="network_tier=${{ matrix.env }}" \
            -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
            -var="repo_pat=${{ secrets.REPO_PAT }}" \
            -var="repo_name=${{ secrets.REPO_NAME }}" \
            -var="restore_from_snapshot=false" \
            -var="snapshot_identifier=null" \
            -auto-approve || echo "‚ö†Ô∏è Terraform destroy completed with warnings"
          
          # Verify cleanup
          REMAINING=$(terraform state list 2>/dev/null | wc -l)
          if [ "$REMAINING" -eq 0 ]; then
            echo "‚úÖ All resources destroyed successfully"
          else
            echo "‚ö†Ô∏è Warning: $REMAINING resources remain in state"
          fi
        else
          echo "‚ÑπÔ∏è No Terraform state found - nothing to destroy"
        fi
        
        echo "‚úÖ Terraform destroy completed for ${{ matrix.env }} environment"

    - name: Generate Execution Report
      if: always()
      working-directory: infra/live
      run: |
        echo "## üèóÔ∏è Infrastructure Execution Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Basic execution details
        echo "### üìã Execution Details" >> $GITHUB_STEP_SUMMARY
        echo "**Action:** ${{ github.event.inputs.action }}" >> $GITHUB_STEP_SUMMARY
        echo "**Network Tier:** ${{ matrix.env }}" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        echo "**Completed:** $(date '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Runner:** ${{ github.event.inputs.runner_type }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Current state and detailed infrastructure info
        echo "### üìä Infrastructure State & Network Design" >> $GITHUB_STEP_SUMMARY
        if terraform state list > /tmp/resources.txt 2>/dev/null; then
          RESOURCE_COUNT=$(wc -l < /tmp/resources.txt)
          echo "**Total Resources:** $RESOURCE_COUNT" >> $GITHUB_STEP_SUMMARY
          
          # Generate network diagram with actual IPs
          K3S_IP=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=health-app-${{ matrix.env }}-k3s-node" "Name=instance-state-name,Values=running" --query "Reservations[0].Instances[0].PublicIpAddress" --output text 2>/dev/null || echo "N/A")
          RUNNER_IP=$(aws ec2 describe-instances --filters "Name=tag:NetworkTier,Values=${{ matrix.env }}" "Name=tag:Name,Values=*runner*" "Name=instance-state-name,Values=running" --query "Reservations[0].Instances[0].PublicIpAddress" --output text 2>/dev/null || echo "N/A")
          RDS_ENDPOINT=$(aws rds describe-db-instances --query "DBInstances[?contains(DBInstanceIdentifier, 'health-app-${{ matrix.env }}')].Endpoint.Address" --output text 2>/dev/null | cut -d'.' -f1 || echo "N/A")
          
          echo "#### üåê Network Architecture" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê" >> $GITHUB_STEP_SUMMARY
          echo "‚îÇ                    AWS Region: ap-south-1                   ‚îÇ" >> $GITHUB_STEP_SUMMARY
          echo "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ matrix.env }}" = "lower" ]; then
            echo "‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ                 LOWER NETWORK (ACTIVE)                 ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ   K3S NODE  ‚îÇ  ‚îÇ GITHUB RUN  ‚îÇ  ‚îÇ    DATABASE     ‚îÇ   ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ $K3S_IP ‚îÇ  ‚îÇ $RUNNER_IP ‚îÇ  ‚îÇ $RDS_ENDPOINT   ‚îÇ   ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ   t2.micro  ‚îÇ  ‚îÇ   t2.micro  ‚îÇ  ‚îÇ   db.t3.micro   ‚îÇ   ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ  Port: 6443 ‚îÇ  ‚îÇ  SSH: 22    ‚îÇ  ‚îÇ   Port: 5432    ‚îÇ   ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ matrix.env }}" = "higher" ]; then
            echo "‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ                HIGHER NETWORK (ACTIVE)                 ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ   K3S NODE  ‚îÇ                  ‚îÇ    DATABASE         ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ $K3S_IP ‚îÇ                  ‚îÇ $RDS_ENDPOINT       ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ   t2.micro  ‚îÇ                  ‚îÇ   db.t3.micro       ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ  Port: 6443 ‚îÇ                  ‚îÇ   Port: 5432        ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ                                                         ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                        ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ GITHUB RUN  ‚îÇ                                        ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ $RUNNER_IP ‚îÇ                                        ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ   t2.micro  ‚îÇ                                        ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                        ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ matrix.env }}" = "monitoring" ]; then
            echo "‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ              MONITORING NETWORK (ACTIVE)               ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ              MONITORING CLUSTER                     ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ         K3s Master + GitHub Runner                  ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ         $K3S_IP + $RUNNER_IP                        ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ         Prometheus + Grafana                        ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îÇ                t2.micro                             ‚îÇ ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ" >> $GITHUB_STEP_SUMMARY
            echo "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "#### üíª Resource Details" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          aws ec2 describe-instances --filters "Name=tag:NetworkTier,Values=${{ matrix.env }}" "Name=instance-state-name,Values=running" --query "Reservations[*].Instances[*].[Tags[?Key=='Name'].Value|[0],InstanceType,PublicIpAddress,PrivateIpAddress,State.Name]" --output table >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No EC2 instances found" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Connection details if resources exist
          if [ "$RESOURCE_COUNT" -gt 0 ]; then
            echo "#### üöÄ Access Information" >> $GITHUB_STEP_SUMMARY
            
            if [ "$K3S_IP" != "None" ] && [ -n "$K3S_IP" ]; then
              echo "**K3s Cluster:** \`ssh -i ~/.ssh/key ubuntu@$K3S_IP\`" >> $GITHUB_STEP_SUMMARY
              echo "**K3s API:** https://$K3S_IP:6443" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [ "$RUNNER_IP" != "None" ] && [ -n "$RUNNER_IP" ]; then
              echo "**GitHub Runner:** \`ssh -i ~/.ssh/key ubuntu@$RUNNER_IP\`" >> $GITHUB_STEP_SUMMARY
              echo "**Runner Labels:** self-hosted, github-runner-${{ matrix.env }}" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [ "$RDS_ENDPOINT" != "None" ] && [ -n "$RDS_ENDPOINT" ]; then
              echo "**Database:** $RDS_ENDPOINT:5432" >> $GITHUB_STEP_SUMMARY
            fi
          fi
        else
          echo "**Status:** No infrastructure deployed" >> $GITHUB_STEP_SUMMARY
        fi