name: Core Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action'
        required: true
        type: choice
        options:
        - deploy
        - destroy
        - plan
        - redeploy
      environment:
        description: 'Network/Environment'
        required: true
        default: 'lower'
        type: choice
        options:
        - lower
        - higher
        - monitoring
        - all
        - cleanup-all
      confirm_destroy:
        description: 'Type "DESTROY" to confirm'
        required: false
        type: string
      restore_from_snapshot:
        description: 'Restore RDS from snapshot'
        required: false
        default: false
        type: boolean
      runner_type:
        description: 'Runner Type'
        required: false
        default: 'aws'
        type: choice
        options:
        - aws
        - github

env:
  AWS_REGION: ap-south-1
  TERRAFORM_VERSION: 1.6.0

jobs:
  infrastructure:
    runs-on: ${{ github.event.inputs.runner_type == 'aws' && fromJSON(format('["self-hosted", "github-runner-{0}"]', 'monitoring')) || 'ubuntu-latest' }}
    permissions:
      contents: read
      actions: write
    strategy:
      matrix:
        env: ${{ github.event.inputs.environment == 'all' && fromJson('["lower", "higher", "monitoring"]') || github.event.inputs.environment == 'cleanup-all' && fromJson('["cleanup"]') || fromJson(format('["{0}"]', github.event.inputs.environment)) }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Terraform Init
      working-directory: infra/two-network-setup
      run: |
        echo "üîç Backend Configuration:"
        echo "- Bucket: ${{ secrets.TF_STATE_BUCKET }}"
        echo "- Key: health-app-${{ matrix.env }}.tfstate"
        echo "- Region: $AWS_REGION"
        
        terraform init \
          -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
          -backend-config="key=health-app-${{ matrix.env }}.tfstate" \
          -backend-config="region=$AWS_REGION"

    - name: Terraform Plan
      working-directory: infra/two-network-setup
      if: github.event.inputs.action == 'plan' || github.event.inputs.action == 'deploy'
      run: |
        echo "üìã Planning infrastructure changes..."
        terraform plan \
          -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
          -var="network_tier=${{ matrix.env }}" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -var="repo_pat=${{ secrets.REPO_PAT }}" \
          -var="repo_name=${{ secrets.REPO_NAME }}" \
          -var="restore_from_snapshot=${{ github.event.inputs.restore_from_snapshot }}" \
          -var="snapshot_identifier=${{ github.event.inputs.restore_from_snapshot == 'true' && 'healthapidb-snapshot' || 'null' }}" \
          -out=tfplan

    - name: Terraform Destroy (for redeploy)
      working-directory: infra/two-network-setup
      if: github.event.inputs.action == 'redeploy'
      run: |
        echo "üßπ Destroying existing resources first..."
        terraform destroy \
          -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
          -var="network_tier=${{ matrix.env }}" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -var="repo_pat=${{ secrets.REPO_PAT }}" \
          -var="repo_name=${{ secrets.REPO_NAME }}" \
          -var="restore_from_snapshot=false" \
          -var="snapshot_identifier=null" \
          -auto-approve || echo "Destroy completed with warnings"

    - name: Terraform Apply
      working-directory: infra/two-network-setup
      if: github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy'
      run: |
        echo "üöÄ Applying infrastructure changes..."
        terraform apply \
          -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
          -var="network_tier=${{ matrix.env }}" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -var="repo_pat=${{ secrets.REPO_PAT }}" \
          -var="repo_name=${{ secrets.REPO_NAME }}" \
          -var="restore_from_snapshot=${{ github.event.inputs.restore_from_snapshot }}" \
          -var="snapshot_identifier=${{ github.event.inputs.restore_from_snapshot == 'true' && 'healthapidb-snapshot' || 'null' }}" \
          -auto-approve
        
        echo "‚úÖ Infrastructure deployed successfully"



    - name: Terraform Destroy
      working-directory: infra/two-network-setup
      if: github.event.inputs.action == 'destroy'
      run: |
        echo "üßπ Destroying infrastructure..."
        
        if [ "${{ github.event.inputs.confirm_destroy }}" != "DESTROY" ]; then
          echo "‚ùå Destroy confirmation required - type 'DESTROY' to confirm"
          exit 1
        fi
        
        terraform destroy \
          -var="environment=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
          -var="network_tier=${{ matrix.env }}" \
          -var="ssh_public_key=${{ secrets.SSH_PUBLIC_KEY }}" \
          -var="repo_pat=${{ secrets.REPO_PAT }}" \
          -var="repo_name=${{ secrets.REPO_NAME }}" \
          -var="restore_from_snapshot=false" \
          -var="snapshot_identifier=null" \
          -auto-approve
        
        echo "‚úÖ Infrastructure destroyed successfully"

    - name: Post-deployment Summary
      if: success() && (github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy')
      working-directory: infra/two-network-setup
      run: |
        echo "‚úÖ Infrastructure deployment completed successfully!"
        echo "üìã Summary for ${{ matrix.env }} network:"
        
        echo "üîç Terraform outputs:"
        terraform output 2>/dev/null || echo "No outputs available"
        
        echo "üöÄ Proceeding to kubeconfig setup and cleanup..."

  validate-runner:
    needs: infrastructure
    if: github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy'
    runs-on: ubuntu-latest
    outputs:
      runner-ready: ${{ steps.check-runner.outputs.ready }}
    strategy:
      matrix:
        env: ${{ github.event.inputs.environment == 'all' && fromJson('["lower", "higher", "monitoring"]') || fromJson(format('["{0}"]', github.event.inputs.environment)) }}
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Check Runner Status
      id: check-runner
      run: |
        echo "üîç Checking if GitHub runner is ready..."
        
        # Get runner instance based on environment
        RUNNER_NAME="health-app-runner-${{ matrix.env }}"
        echo "Looking for runner: $RUNNER_NAME"
        
        # Check if runner instance is running
        RUNNER_STATUS=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=$RUNNER_NAME" \
                   "Name=instance-state-name,Values=running" \
          --query 'Reservations[0].Instances[0].State.Name' \
          --output text 2>/dev/null || echo "None")
        
        if [[ "$RUNNER_STATUS" == "running" ]]; then
          echo "‚úÖ Runner instance is running"
          
          # Wait for runner to be online (max 5 minutes)
          echo "‚è≥ Waiting for runner to be online..."
          for i in {1..30}; do
            # Check if runner is online via GitHub API
            RUNNER_ONLINE=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
              "https://api.github.com/repos/${{ github.repository }}/actions/runners" \
              | jq -r '.runners[] | select(.name | contains("github-runner-${{ matrix.env }}")) | .status' 2>/dev/null || echo "")
            
            if [[ "$RUNNER_ONLINE" == "online" ]]; then
              echo "‚úÖ Runner is online and ready"
              echo "ready=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            
            echo "‚è≥ Attempt $i/30 - Runner not online yet..."
            sleep 10
          done
          
          echo "‚ùå Runner instance running but not online after 5 minutes"
          echo "ready=false" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Runner instance not running: $RUNNER_STATUS"
          echo "ready=false" >> $GITHUB_OUTPUT
        fi

  setup-kubeconfig:
    needs: [infrastructure, validate-runner]
    if: needs.validate-runner.outputs.runner-ready == 'true'
    runs-on: ${{ github.event.inputs.environment == 'lower' && fromJSON('["self-hosted", "github-runner-lower"]') || github.event.inputs.environment == 'higher' && fromJSON('["self-hosted", "github-runner-higher"]') || github.event.inputs.environment == 'monitoring' && fromJSON('["self-hosted", "github-runner-monitoring"]') || fromJSON('["self-hosted", "github-runner-lower"]') }}
    strategy:
      matrix:
        env: ${{ github.event.inputs.environment == 'all' && fromJson('["lower", "higher", "monitoring"]') || fromJson(format('["{0}"]', github.event.inputs.environment)) }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Terraform Init (for outputs)
      working-directory: infra/two-network-setup
      run: |
        terraform init \
          -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
          -backend-config="key=health-app-${{ matrix.env }}.tfstate" \
          -backend-config="region=$AWS_REGION"

    - name: Install kubectl and GitHub CLI
      run: |
        # Install kubectl
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/
        
        # Install GitHub CLI
        curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
        echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
        sudo apt update
        sudo apt install gh -y

    - name: Setup Kubeconfig
      env:
        SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        TF_STATE_BUCKET: ${{ secrets.TF_STATE_BUCKET }}
      run: |
        chmod +x scripts/setup-kubeconfig-post-deploy.sh
        ./scripts/setup-kubeconfig-post-deploy.sh ${{ matrix.env }}

  cleanup-orphaned:
    needs: [infrastructure, setup-kubeconfig]
    if: success() && (github.event.inputs.action == 'deploy' || github.event.inputs.action == 'redeploy')
    runs-on: ubuntu-latest
    strategy:
      matrix:
        env: ${{ github.event.inputs.environment == 'all' && fromJson('["lower", "higher", "monitoring"]') || fromJson(format('["{0}"]', github.event.inputs.environment)) }}
    
    steps:
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Cleanup Orphaned Resources
      run: |
        echo "üßπ Cleaning up orphaned resources for ${{ matrix.env }}..."
        
        # Get current managed resources from terraform state
        MANAGED_INSTANCES=$(aws ec2 describe-instances \
          --filters "Name=tag:ManagedBy,Values=terraform" \
                   "Name=tag:Environment,Values=${{ matrix.env == 'lower' && 'dev' || matrix.env == 'higher' && 'prod' || 'monitoring' }}" \
                   "Name=instance-state-name,Values=running" \
          --query 'Reservations[].Instances[].InstanceId' \
          --output text)
        
        echo "‚úÖ Managed instances: $MANAGED_INSTANCES"
        
        # Find orphaned instances (same name pattern but not managed by current terraform)
        ORPHANED_K3S=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=*k3s*" \
                   "Name=instance-state-name,Values=running" \
          --query "Reservations[].Instances[?!contains('$MANAGED_INSTANCES', InstanceId)].InstanceId" \
          --output text)
        
        ORPHANED_RUNNERS=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=*runner*" \
                   "Name=instance-state-name,Values=running" \
          --query "Reservations[].Instances[?!contains('$MANAGED_INSTANCES', InstanceId)].InstanceId" \
          --output text)
        
        # Terminate orphaned instances
        if [[ -n "$ORPHANED_K3S" ]]; then
          echo "üóëÔ∏è Terminating orphaned K3s instances: $ORPHANED_K3S"
          aws ec2 terminate-instances --instance-ids $ORPHANED_K3S
        fi
        
        if [[ -n "$ORPHANED_RUNNERS" ]]; then
          echo "üóëÔ∏è Terminating orphaned runner instances: $ORPHANED_RUNNERS"
          aws ec2 terminate-instances --instance-ids $ORPHANED_RUNNERS
        fi
        
        # Clean up orphaned security groups (after instances are terminated)
        sleep 30
        echo "üîí Cleaning up orphaned security groups..."
        
        aws ec2 describe-security-groups \
          --filters "Name=group-name,Values=*k3s*,*runner*" \
          --query 'SecurityGroups[?length(IpPermissions) == `0` && length(IpPermissionsEgress) <= `1`].[GroupId,GroupName]' \
          --output text | while read sg_id sg_name; do
            if [[ -n "$sg_id" ]]; then
              echo "Deleting unused security group: $sg_id ($sg_name)"
              aws ec2 delete-security-group --group-id $sg_id 2>/dev/null || echo "Could not delete $sg_id"
            fi
        done
        
        echo "‚úÖ Cleanup completed for ${{ matrix.env }}"