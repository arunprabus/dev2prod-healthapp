# üè• Health App Infrastructure Repository

## Production-Ready Infrastructure with Blue-Green Deployment

This repository contains the infrastructure code for the Health App platform. The application code has been moved to separate repositories to follow separation of concerns.

## Repository Structure

- `infra/`: Infrastructure as Code (IaC) using Terraform
  - `modules/`: Reusable Terraform modules
  - `environments/`: Environment-specific configurations
- `.github/workflows/`: CI/CD pipelines
  - `infra-deploy.yml`: Infrastructure deployment pipeline
  - `app-deploy.yml`: Application deployment pipeline (triggers deployments to infrastructure)

## Related Repositories

- [Health API](https://github.com/arunprabus/health-api): Backend API code
- [Health Frontend](https://github.com/arunprabus/health-dash): Frontend application code

## Infrastructure Deployment

The infrastructure code manages the following resources:

- **VPC and networking components** (isolated per environment)
- **K3s clusters** for cost-effective Kubernetes (FREE TIER)
- **RDS database instances** (FREE TIER eligible)
- **Multi-environment setup** (dev: 10.0.0.0/16, test: 10.2.0.0/16, prod: 10.1.0.0/16)
- **Deployment configurations** via Kubernetes manifests

## Deployment Strategy

### Infrastructure

The infrastructure is deployed using the GitHub Actions workflow in `.github/workflows/infra-deploy.yml`. This creates the base infrastructure for each environment (development, test, production).

### Applications

Application deployments are handled through the following process:

1. Code is pushed to the application repositories (HealthApi or HealthFrontend)
2. The `.github/workflows/app-deploy.yml` workflow is triggered
3. The workflow builds the application and pushes it to the container registry
4. ArgoCD detects the changes and deploys the application to the appropriate environment

### Environment Targeting

- **Development Environment**: Triggered by pushes to the `develop` branch
- **Test Environment**: Triggered by pushes to the `staging` branch
- **Production Environment**: Triggered by pushes to the `main` branch

## Getting Started

### Prerequisites

- AWS CLI configured with appropriate credentials
- Terraform CLI (v1.6.0 or later)
- kubectl

### Deploying Infrastructure

You can deploy the infrastructure using the GitHub Actions workflow or manually:

```bash
cd infra
terraform init \
  -backend-config="bucket=your-terraform-state-bucket" \
  -backend-config="key=health-app-dev.tfstate" \
  -backend-config="region=ap-south-1"
terraform apply -var-file="environments/dev.tfvars"
```

## Maintenance

The separation of application and infrastructure code allows for:

1. Independent scaling of infrastructure without affecting application code
2. Clearer responsibility boundaries
3. Simplified CI/CD pipelines
4. Better security and access control
> üöÄ Enterprise-grade multi-environment setup with EKS, RDS, and **Blue-Green deployment strategy**‚Äîperfect for learning production DevOps practices.

---

## üß± Network Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       AWS Region: ap-south-1                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ                 LOWER NETWORK (10.0.0.0/16)                     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îÇ  DEV ENV     ‚îÇ     ‚îÇ  TEST ENV    ‚îÇ                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îÇ EKS + RDS    ‚îÇ     ‚îÇ EKS + RDS    ‚îÇ                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ                HIGHER NETWORK (10.1.0.0/16)                     ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îÇ  PROD ENV    ‚îÇ                                                ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îÇ EKS + RDS    ‚îÇ                                                ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ ‚îÇ               MONITORING NETWORK (10.3.0.0/16)                  ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      VPC Peering          ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îÇ  MONITORING ENV                   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄConnection‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îÇ  EKS + Splunk + Prometheus        ‚îÇ                           ‚îÇ   ‚îÇ
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

> üîí **Enhanced Architecture**: Complete network isolation between Production and Dev/Test environments with centralized monitoring that has visibility into all environments.

---

## üí∞ Cost Comparison

### üÜì **Current Setup: 100% FREE TIER**
| Resource | Usage | Free Tier Limit | Monthly Cost |
|----------|-------|-----------------|-------------|
| EC2 t2.micro | 720 hrs | 750 hrs/month | **$0** |
| RDS db.t3.micro | 720 hrs | 750 hrs/month | **$0** |
| EBS Storage | 28GB | 30GB/month | **$0** |
| VPC + Networking | Unlimited | Unlimited | **$0** |
| **Total** | | | **$0/month** |

### üí∞ Alternative: EKS Setup (Production)
| Resource | Quantity | Free Tier | Monthly Cost |
|----------|----------|-----------|-------------|
| EKS Control Plane | 1 | ‚ùå Not Free | **$73** |
| NAT Gateway | 1 | ‚ùå Not Free | **$45** |
| EC2 t2.micro | 1 | 750 hrs | $0 |
| RDS db.t3.micro | 1 | 750 hrs | $0 |
| **Total** | | | **$118/month** |

### üìä **Cost Savings Achieved: 95%+**
| Setup | Monthly Cost | Savings |
|-------|-------------|----------|
| **K3s (Current)** | **$0** | **Baseline** |
| EKS Alternative | $118 | -$118/month |
| **Multi-Env K3s** | **$0** | **vs $354/month** |

---

## üöÄ Quick Start

### üÜì **Deploy Instructions: $0 Cost Infrastructure**

#### **‚öôÔ∏è Prerequisites**
1. **AWS Account** with Free Tier available
2. **SSH Key Pair** generated
3. **GitHub Secrets** configured

#### **üöÄ Deployment Steps**

**Step 1: Generate SSH Key**
```bash
# Generate SSH key if you don't have one
ssh-keygen -t rsa -b 4096 -f ~/.ssh/aws-key

# Copy your public key content
cat ~/.ssh/aws-key.pub
```

**Step 2: Configure GitHub Secrets**
Go to **Settings** ‚Üí **Secrets and variables** ‚Üí **Actions** and add:
- `AWS_ACCESS_KEY_ID`: Your AWS access key
- `AWS_SECRET_ACCESS_KEY`: Your AWS secret key  
- `SSH_PUBLIC_KEY`: Your SSH public key content (from Step 1)

**Step 3: Deploy via GitHub Actions**
1. Go to **Actions** ‚Üí **Infrastructure Deployment**
2. Select **environment**: `dev`
3. Select **terraform_action**: `apply`
4. Click **Run workflow**

**Step 4: Access Your Infrastructure**
```bash
# SSH to K3s node (get IP from GitHub Actions output)
ssh -i ~/.ssh/aws-key ubuntu@<EC2_PUBLIC_IP>

# Access Kubernetes cluster
kubectl --server=https://<EC2_PUBLIC_IP>:6443 get nodes
```

**Step 5: Cleanup When Done**
1. Go to **Actions** ‚Üí **Infrastructure Cleanup**
2. Select **environment** (dev/test/prod/monitoring/all)
3. Type **"DESTROY"** in confirmation field
4. Click **Run workflow**
5. All resources will be deleted (cost returns to $0)

#### **üí∞ Cost Verification**
| Resource | Usage | Free Tier | Status |
|----------|-------|-----------|--------|
| EC2 t2.micro | 720h/month | 750h limit | ‚úÖ **$0** |
| RDS db.t3.micro | 720h/month | 750h limit | ‚úÖ **$0** |
| EBS Storage | ~28GB | 30GB limit | ‚úÖ **$0** |
| VPC + Networking | Unlimited | Always free | ‚úÖ **$0** |
| **Total Monthly Cost** | | | **$0** |

#### **üõ°Ô∏è Safety Features**
- ‚úÖ **Instance type locked** to t2.micro (FREE TIER)
- ‚úÖ **RDS locked** to db.t3.micro (FREE TIER)
- ‚úÖ **No NAT Gateway** (would cost $45/month)
- ‚úÖ **No Load Balancers** (would cost $18/month each)
- ‚úÖ **Storage limits** enforced (20GB max)

#### **üîÑ Multi-Environment Deployment**
```bash
# Deploy Test Environment
Actions ‚Üí Infrastructure Deployment ‚Üí environment: "test" ‚Üí apply

# Deploy Production Environment  
Actions ‚Üí Infrastructure Deployment ‚Üí environment: "prod" ‚Üí apply

# Each environment: $0/month
# Total all environments: $0/month
```

#### **üìä Alternative: Manual Deployment**
```bash
# Clone repository
git clone https://github.com/arunprabus/dev2prod-healthapp.git
cd dev2prod-healthapp/infra

# Initialize Terraform
terraform init

# Plan deployment (verify $0 cost)
terraform plan -var-file="environments/dev.tfvars" -var="ssh_public_key=$(cat ~/.ssh/aws-key.pub)"

# Apply (deploy infrastructure)
terraform apply -var-file="environments/dev.tfvars" -var="ssh_public_key=$(cat ~/.ssh/aws-key.pub)"

# Destroy when done (optional)
terraform destroy -var-file="environments/dev.tfvars" -var="ssh_public_key=$(cat ~/.ssh/aws-key.pub)"
```

## ‚öôÔ∏è Configuration Management

### **Environment Variables (Configurable)**
| Variable | Default | Purpose |
|----------|---------|----------|
| `AWS_REGION` | `ap-south-1` | Deployment region |
| `EKS_CLUSTER_NAME` | `health-app-cluster` | Cluster base name |
| `CONTAINER_REGISTRY` | `ghcr.io` | Container registry |
| `REGISTRY_NAMESPACE` | `your-organization` | Registry namespace |
| `TERRAFORM_VERSION` | `1.6.0` | Terraform version |
| `KUBECTL_TIMEOUT` | `300s` | K8s operation timeout |

### **Multi-Environment Support**
- **Dev**: Fast deployments, shorter timeouts
- **Test**: Balanced configuration for testing
- **Prod**: Conservative settings, longer timeouts

### **Multi-Region Ready**
```yaml
# Asia Pacific
AWS_REGION: "ap-south-1"

# US East
AWS_REGION: "us-east-1"

# Europe
AWS_REGION: "eu-west-1"
```

## üè¢ Enterprise Benefits

### **Multi-Customer Deployments**
- **Isolated configurations** per customer
- **Separate AWS accounts** and regions
- **Custom branding** and domain names
- **Independent scaling** policies

### **Regional Compliance**
- **Data residency** requirements
- **GDPR compliance** in EU regions
- **Local regulations** adherence
- **Disaster recovery** across regions

### **Environment Isolation**
- **Different settings** per environment
- **Resource sizing** optimization
- **Security policies** per env
- **Cost allocation** tracking

### **Zero Code Changes**
- **Configuration-driven** deployments
- **Template reusability** across projects
- **Rapid environment** provisioning
- **Consistent deployments** everywhere

### **Centralized Configuration**
- **GitHub variables** management
- **Environment-specific** secrets
- **Version-controlled** configurations
- **Audit trail** for changes

## üöÄ Usage Examples

### **Global Company Setup**
```yaml
# US Production
AWS_REGION: "us-east-1"
EKS_CLUSTER_NAME: "health-app-us-prod"
CONTAINER_REGISTRY: "your-company.dkr.ecr.us-east-1.amazonaws.com"
REGISTRY_NAMESPACE: "production"
MIN_REPLICAS: "3"
MAX_REPLICAS: "20"

# EU Production  
AWS_REGION: "eu-west-1"
EKS_CLUSTER_NAME: "health-app-eu-prod"
CONTAINER_REGISTRY: "your-company.dkr.ecr.eu-west-1.amazonaws.com"
REGISTRY_NAMESPACE: "production-eu"
MIN_REPLICAS: "2"
MAX_REPLICAS: "15"

# APAC Production
AWS_REGION: "ap-south-1" 
EKS_CLUSTER_NAME: "health-app-apac-prod"
CONTAINER_REGISTRY: "your-company.dkr.ecr.ap-south-1.amazonaws.com"
REGISTRY_NAMESPACE: "production-apac"
MIN_REPLICAS: "2"
MAX_REPLICAS: "10"
```

### **Multi-Tenant SaaS Setup**
```yaml
# Customer A (Enterprise)
REGISTRY_NAMESPACE: "customer-a"
EKS_CLUSTER_NAME: "customer-a-cluster"
AWS_REGION: "us-west-2"
MIN_REPLICAS: "5"
MAX_REPLICAS: "50"
KUBECTL_TIMEOUT: "600s"
CLEANUP_DELAY: "120"

# Customer B (Startup)
REGISTRY_NAMESPACE: "customer-b"  
EKS_CLUSTER_NAME: "customer-b-cluster"
AWS_REGION: "us-east-1"
MIN_REPLICAS: "2"
MAX_REPLICAS: "10"
KUBECTL_TIMEOUT: "300s"
CLEANUP_DELAY: "30"
```

### **Development vs Production**
```yaml
# Development Environment
AWS_REGION: "ap-south-1"
EKS_CLUSTER_NAME: "health-app-dev"
CONTAINER_REGISTRY: "ghcr.io"
MIN_REPLICAS: "1"
MAX_REPLICAS: "3"
KUBECTL_TIMEOUT: "180s"
CLEANUP_DELAY: "10"
LB_WAIT_TIME: "30"

# Production Environment
AWS_REGION: "us-east-1"
EKS_CLUSTER_NAME: "health-app-prod"
CONTAINER_REGISTRY: "your-company.dkr.ecr.us-east-1.amazonaws.com"
MIN_REPLICAS: "3"
MAX_REPLICAS: "20"
KUBECTL_TIMEOUT: "600s"
CLEANUP_DELAY: "120"
LB_WAIT_TIME: "180"
```

---

## üîÑ Blue-Green Deployment Strategy

### How It Works
1. **Blue Environment**: Current production version
2. **Green Environment**: New version deployment
3. **Traffic Switch**: Instant cutover with zero downtime
4. **Auto Rollback**: Automatic revert on failure

### Deployment Flow
```
Blue (Live) ‚îÄ‚îÄ‚îê
              ‚îú‚îÄ‚Üí Load Balancer ‚îÄ‚îÄ‚Üí Users
Green (New) ‚îÄ‚îÄ‚îò
```

## üåê Application Access

| Environment | EKS Cluster | Frontend | Backend | Status |
|-------------|-------------|----------|---------|--------|
| Dev | health-app-cluster-dev | LoadBalancer | LoadBalancer | Active |
| Test | health-app-cluster-test | LoadBalancer | LoadBalancer | Active |
| Prod | health-app-cluster-prod | LoadBalancer | LoadBalancer | Blue-Green |

---

## üõ†Ô∏è Deployment Commands

### GitHub Actions Workflows
| Workflow | Trigger | Description |
|----------|---------|-------------|
| `Infrastructure Deployment` | Manual | Deploy K3s infrastructure ($0 cost) |
| `Infrastructure Cleanup` | Manual | **Destroy all resources** (type "DESTROY" to confirm) |
| `Manual Rollback` | Manual | Instant rollback to previous version |
| `Cost Monitor` | Schedule | Monitor AWS costs and usage |

### Manual Operations
```bash
# Check deployment status
kubectl get deployments
kubectl get services

# View current active color
kubectl get service health-api-service -o jsonpath='{.spec.selector.color}'
```

## üö® Rollback Procedures

### 1. GitHub Actions Rollback (Recommended)
1. Go to **Actions** ‚Üí **Manual Rollback**
2. Select environment (dev/test/prod)
3. Click **Run workflow**

### 2. Emergency Production Rollback (Fastest)
```bash
aws eks update-kubeconfig --region ap-south-1 --name health-app-cluster-prod
kubectl patch service health-api-service -p '{"spec":{"selector":{"color":"blue"}}}'
kubectl patch service frontend-service -p '{"spec":{"selector":{"color":"blue"}}}'
```

### 3. Script-based Rollback
```bash
chmod +x scripts/rollback.sh
./scripts/rollback.sh prod    # Production
./scripts/rollback.sh test    # Test
./scripts/rollback.sh dev     # Development
```

### 4. Environment-Specific Commands
```bash
# Dev Environment
aws eks update-kubeconfig --region ap-south-1 --name health-app-cluster-dev
kubectl patch service health-api-service -p '{"spec":{"selector":{"color":"blue"}}}'

# Test Environment
aws eks update-kubeconfig --region ap-south-1 --name health-app-cluster-test
kubectl patch service health-api-service -p '{"spec":{"selector":{"color":"blue"}}}'

# Production Environment
aws eks update-kubeconfig --region ap-south-1 --name health-app-cluster-prod
kubectl patch service health-api-service -p '{"spec":{"selector":{"color":"blue"}}}'
```

> ‚ö° **Rollback is instant** - switches traffic between blue/green versions with zero downtime

---

## üí∏ Cost Control

```bash
make stop-all     # Stop all EC2 (save costs)
make start-all    # Restart EC2 instances
make destroy-all  # Tear everything down
```

---

## üîí Security & Isolation

- ‚úÖ Two distinct VPCs (Lower: Dev/Test, Higher: Prod)
- ‚úÖ Complete isolation‚Äîno cross-VPC traffic
- ‚úÖ SSH key-based login
- ‚úÖ Public subnets only (no NAT Gateway)

---

## üìÅ Repository Structure

```
‚îú‚îÄ‚îÄ .github/workflows/     # CI/CD pipelines
‚îÇ   ‚îú‚îÄ‚îÄ deploy.yml        # Blue-green deployment
‚îÇ   ‚îú‚îÄ‚îÄ infra-deploy.yml  # Infrastructure setup
‚îÇ   ‚îî‚îÄ‚îÄ infra-shutdown.yml # Cost management
‚îú‚îÄ‚îÄ infra/                # Terraform infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ modules/          # Reusable modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eks/          # EKS module ($73/month)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ k3s/          # K3s module (FREE)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vpc/          # VPC module
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rds/          # RDS module
‚îÇ   ‚îú‚îÄ‚îÄ envs/             # Environment-specific configs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev/          # EKS dev environment
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qa/           # EKS qa environment
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prod/         # EKS prod environment
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ free-tier/    # K3s FREE environment
‚îÇ   ‚îî‚îÄ‚îÄ backend-configs/  # Terraform state configs
‚îú‚îÄ‚îÄ k8s/                  # Kubernetes manifests
‚îÇ   ‚îú‚îÄ‚îÄ health-api-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ frontend-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ hpa.yaml             # Horizontal Pod Autoscaler
‚îÇ   ‚îú‚îÄ‚îÄ vpa.yaml             # Vertical Pod Autoscaler
‚îÇ   ‚îú‚îÄ‚îÄ cluster-autoscaler.yaml  # Cluster scaling
‚îÇ   ‚îú‚îÄ‚îÄ advanced-hpa.yaml    # Custom metrics scaling
‚îÇ   ‚îú‚îÄ‚îÄ rbac.yaml            # Security policies
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.yaml      # Prometheus setup
‚îÇ   ‚îú‚îÄ‚îÄ logging.yaml         # Centralized logging
‚îÇ   ‚îú‚îÄ‚îÄ canary-rollout.yaml  # Advanced deployment
‚îÇ   ‚îî‚îÄ‚îÄ argocd-app.yaml      # GitOps setup
‚îî‚îÄ‚îÄ README.md
```

## üîß Advanced Deployment Options

### 1. Canary Deployment
```bash
# Install Argo Rollouts
kubectl create namespace argo-rollouts
kubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml

# Deploy canary
kubectl apply -f k8s/canary-rollout.yaml
```

### 2. GitOps with ArgoCD
```bash
# Install ArgoCD
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Deploy application
kubectl apply -f k8s/argocd-app.yaml
```

## üè¢ Enterprise Features

### Security & Compliance
- üîí **RBAC**: Role-based access control
- üõ°Ô∏è **Pod Security**: Non-root containers, read-only filesystem
- üîç **Security Scanning**: Trivy vulnerability scanning
- üåê **Network Policies**: Micro-segmentation

### Monitoring & Observability
- üìä **Prometheus**: Metrics collection
- üö® **Alerting**: Automated incident detection
- üìÑ **Centralized Logging**: Fluent Bit + CloudWatch
- üí∞ **Cost Monitoring**: Weekly spend alerts

### Auto-Scaling & Performance
- üìà **Horizontal Scaling (HPA)**: 2-10 pods based on CPU/memory
- üìâ **Vertical Scaling (VPA)**: Auto-adjusts pod resources
- üè¢ **Cluster Scaling**: Auto-adds/removes nodes
- üìä **Advanced Metrics**: Custom scaling triggers
- üß™ **Load Testing**: Automated performance validation
- üîÑ **Blue-Green**: Zero-downtime deployments
- üíæ **Backup**: Automated DynamoDB backups

## üß™ Learning Highlights

### üÜì Free Tier Learning (K3s Setup)
- üîÑ **Kubernetes Fundamentals**: Pods, services, deployments
- üíª **EC2 Management**: SSH, user-data, security groups
- üóæ **Database Integration**: RDS connection from K3s
- üîê **Networking**: VPC, subnets, security groups
- üõ†Ô∏è **Infrastructure as Code**: Terraform modules
- üí∞ **Cost Optimization**: 100% free tier usage

### üíº Production Learning (EKS Setup)
- üîÑ **Blue-Green Deployment**: Zero-downtime deployments
- ‚öôÔ∏è **EKS Management**: Production Kubernetes
- üóÑÔ∏è **DynamoDB + S3**: Serverless data layer
- üîÅ **Multi-environment**: Dev/Test/Prod isolation
- üîê **Security**: IAM roles, secrets management
- üìä **Monitoring**: Health checks, rollback automation
- üöÄ **CI/CD**: GitHub Actions automation

## üéØ Deployment & Scaling Strategies

### Deployment Strategies
| Strategy | Downtime | Risk | Complexity | Rollback Time | Use Case |
|----------|----------|------|------------|---------------|----------|
| Rolling | Minimal | Medium | Low | 2-5 min | Development |
| Blue-Green | Zero | Low | Medium | **Instant** | **Current Setup** |
| Canary | Zero | Very Low | High | Instant | Production |
| A/B Testing | Zero | Low | High | Instant | Feature testing |

### Auto-Scaling Strategies
| Type | Scope | Trigger | Response Time | Cost Impact |
|------|-------|---------|---------------|-------------|
| **HPA** | Pod replicas | CPU/Memory/Custom | 30-60s | Medium |
| **VPA** | Pod resources | Resource usage | 2-5 min | Low |
| **Cluster** | Node count | Pod scheduling | 2-3 min | High |
| **Predictive** | All levels | ML forecasting | Proactive | Optimized |

## üìà Auto-Scaling Architecture

### 3-Tier Scaling Strategy
```
üìä Load Increases
    ‚Üì
üîÑ HPA: Scales pods (2‚Üí10)
    ‚Üì
üìâ VPA: Adjusts resources per pod
    ‚Üì
üè¢ Cluster: Adds/removes nodes
    ‚Üì
‚ö° Full auto-scaling achieved!
```

### Horizontal Pod Autoscaler (HPA)
- **Health API**: 2-10 replicas
- **Frontend**: 2-5 replicas
- **Triggers**: CPU > 70%, Memory > 80%
- **Advanced**: Custom metrics (RPS, queue length)

### Vertical Pod Autoscaler (VPA)
- **Auto-adjusts**: CPU/Memory requests & limits
- **Health API**: 100m-1000m CPU, 128Mi-1Gi memory
- **Frontend**: 50m-500m CPU, 64Mi-512Mi memory

### Cluster Autoscaler
- **Node scaling**: Adds EC2 instances when needed
- **Cost optimization**: Removes unused nodes
- **Multi-AZ**: Distributes across availability zones

## üîç Monitoring & Verification

### Auto-Scaling Status
```bash
# Monitor HPA status
kubectl get hpa -w

# Check VPA recommendations
kubectl get vpa -w

# View resource usage
kubectl top pods
kubectl top nodes

# Scaling events
kubectl get events --field-selector reason=ScalingReplicaSet
```

### Manual Scaling (if needed)
```bash
# Manual horizontal scaling
kubectl scale deployment health-api --replicas=5

# Check current scaling status
kubectl describe hpa health-api-hpa
kubectl describe vpa health-api-vpa
```

### Check Current Status
```bash
# View active deployment color
kubectl get service health-api-service -o jsonpath='{.spec.selector.color}'

# List all deployments
kubectl get deployments -l app=health-api

# Check service health
kubectl get services
kubectl get pods -l app=health-api
```

### Troubleshooting
```bash
# View deployment logs
kubectl logs -l app=health-api,color=green

# Check pod status
kubectl describe pods -l app=health-api

# View recent events
kubectl get events --sort-by=.metadata.creationTimestamp
```

---

## üìÑ Complete Variables & Secrets Reference

### **Repository Variables (GitHub Settings ‚Üí Variables)**

#### **Core Configuration**
```yaml
AWS_REGION: "ap-south-1"                    # AWS deployment region
EKS_CLUSTER_NAME: "health-app-cluster"       # Base cluster name
CONTAINER_REGISTRY: "ghcr.io"               # Container registry URL
REGISTRY_NAMESPACE: "your-username"          # Registry namespace
```

#### **Tool Versions**
```yaml
TERRAFORM_VERSION: "1.6.0"                  # Terraform version
KUBECTL_VERSION: "latest"                   # kubectl version
```

#### **Deployment Timeouts**
```yaml
KUBECTL_TIMEOUT: "300s"                     # Kubernetes operations timeout
CLEANUP_DELAY: "30"                         # Seconds before cleanup
LB_WAIT_TIME: "60"                          # Load balancer wait time
HEALTH_CHECK_RETRIES: "5"                   # Health check retry count
```

#### **Auto-Scaling Configuration**
```yaml
MIN_REPLICAS: "2"                           # Minimum pod replicas
MAX_REPLICAS: "10"                          # Maximum pod replicas
```

### **Repository Secrets (GitHub Settings ‚Üí Secrets)**

#### **AWS Credentials**
```yaml
AWS_ACCESS_KEY_ID: "AKIA..."                # AWS access key
AWS_SECRET_ACCESS_KEY: "xyz123..."          # AWS secret key
```

#### **Notifications**
```yaml
SLACK_WEBHOOK_URL: "https://hooks.slack.com/..."  # Slack notifications
```

#### **Optional: Environment-Specific Secrets**
```yaml
# Development
AWS_ACCESS_KEY_ID_DEV: "AKIA..."            # Dev AWS credentials
AWS_SECRET_ACCESS_KEY_DEV: "xyz123..."

# Production
AWS_ACCESS_KEY_ID_PROD: "AKIA..."           # Prod AWS credentials
AWS_SECRET_ACCESS_KEY_PROD: "xyz123..."
```

### **Environment-Specific Variables**

#### **Development Environment**
```yaml
AWS_REGION: "ap-south-1"
EKS_CLUSTER_NAME: "health-app-dev"
CONTAINER_REGISTRY: "ghcr.io"
REGISTRY_NAMESPACE: "dev-team"
MIN_REPLICAS: "1"
MAX_REPLICAS: "3"
KUBECTL_TIMEOUT: "180s"
CLEANUP_DELAY: "10"
LB_WAIT_TIME: "30"
```

#### **Test Environment**
```yaml
AWS_REGION: "ap-south-1"
EKS_CLUSTER_NAME: "health-app-test"
CONTAINER_REGISTRY: "ghcr.io"
REGISTRY_NAMESPACE: "test-team"
MIN_REPLICAS: "2"
MAX_REPLICAS: "5"
KUBECTL_TIMEOUT: "240s"
CLEANUP_DELAY: "20"
LB_WAIT_TIME: "45"
```

#### **Production Environment**
```yaml
AWS_REGION: "us-east-1"
EKS_CLUSTER_NAME: "health-app-prod"
CONTAINER_REGISTRY: "your-company.dkr.ecr.us-east-1.amazonaws.com"
REGISTRY_NAMESPACE: "production"
MIN_REPLICAS: "3"
MAX_REPLICAS: "20"
KUBECTL_TIMEOUT: "600s"
CLEANUP_DELAY: "120"
LB_WAIT_TIME: "180"
```

### **Sample Multi-Region Configuration**

#### **US Region (Primary)**
```yaml
AWS_REGION: "us-east-1"
EKS_CLUSTER_NAME: "health-app-us"
CONTAINER_REGISTRY: "123456789.dkr.ecr.us-east-1.amazonaws.com"
REGISTRY_NAMESPACE: "us-production"
```

#### **EU Region (GDPR Compliance)**
```yaml
AWS_REGION: "eu-west-1"
EKS_CLUSTER_NAME: "health-app-eu"
CONTAINER_REGISTRY: "123456789.dkr.ecr.eu-west-1.amazonaws.com"
REGISTRY_NAMESPACE: "eu-production"
```

#### **APAC Region (Local Performance)**
```yaml
AWS_REGION: "ap-south-1"
EKS_CLUSTER_NAME: "health-app-apac"
CONTAINER_REGISTRY: "123456789.dkr.ecr.ap-south-1.amazonaws.com"
REGISTRY_NAMESPACE: "apac-production"
```

### **Quick Setup Commands**

```bash
# Set repository variables using GitHub CLI
gh variable set AWS_REGION --body "ap-south-1"
gh variable set EKS_CLUSTER_NAME --body "health-app-cluster"
gh variable set CONTAINER_REGISTRY --body "ghcr.io"
gh variable set REGISTRY_NAMESPACE --body "your-organization"
gh variable set MIN_REPLICAS --body "2"
gh variable set MAX_REPLICAS --body "10"

# Set repository secrets
gh secret set AWS_ACCESS_KEY_ID --body "AKIA..."
gh secret set AWS_SECRET_ACCESS_KEY --body "xyz123..."
gh secret set SLACK_WEBHOOK_URL --body "https://hooks.slack.com/..."

# Set environment-specific variables
gh variable set AWS_REGION --env dev --body "ap-south-1"
gh variable set AWS_REGION --env prod --body "us-east-1"
```

---

**üéì Perfect for mastering enterprise-grade deployment strategies!**
